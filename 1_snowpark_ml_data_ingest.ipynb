{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion\n",
    "\n",
    "The `diamonds` dataset has been widely used in data science and machine learning. We will use it to demonstrate Snowflake's native data science transformers in terms of database functionality and Spark & Pandas comportablity, using non-synthetic and statistically appropriate data that is well known to the ML community.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Secure Connection to Snowflake\n",
    "\n",
    "*Other connection options include Username/Password, MFA, OAuth, Okta, SSO. For more information, refer to the [Python Connector](https://docs.snowflake.com/en/developer-guide/python-connector/python-connector-example) documentation.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark for Python\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark.types import StructType, StructField, FloatType, StringType, IntegerType\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "# data science libs\n",
    "import numpy as np\n",
    "\n",
    "# misc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User                        : SIKHADAS\n",
      "Role                        : \"ACCOUNTADMIN\"\n",
      "Database                    : \"ML_HOL_DB\"\n",
      "Schema                      : \"ML_HOL_SCHEMA\"\n",
      "Warehouse                   : \"ML_HOL_WH\"\n",
      "Snowflake version           : 7.22.1\n",
      "Snowpark for Python version : 1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Make a Snowpark Connection\n",
    "\n",
    "################################################################################################################\n",
    "#  You can also use the SnowSQL Client to configure your connection params:\n",
    "#  https://docs.snowflake.com/en/user-guide/snowsql-install-config.html\n",
    "#\n",
    "#  >>> from snowflake.ml.utils import connection_params\n",
    "#  >>> session = Session.builder.configs(connection_params.SnowflakeLoginOptions()\n",
    "#  >>> ).create()   \n",
    "#\n",
    "#  NOTE: If you have named connection params then specify the connection name\n",
    "#  Example:\n",
    "#  \n",
    "#  >>> session = Session.builder.configs(\n",
    "#  >>> connection_params.SnowflakeLoginOptions(connection_name='connections.snowml')\n",
    "#  >>> ).create()\n",
    "#\n",
    "#################################################################################################################\n",
    "\n",
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open('connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('User                        : {}'.format(snowflake_environment[0][0]))\n",
    "print('Role                        : {}'.format(session.get_current_role()))\n",
    "print('Database                    : {}'.format(session.get_current_database()))\n",
    "print('Schema                      : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse                   : {}'.format(session.get_current_warehouse()))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][1]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage the `diamonds` CSV file to be read into the Snowpark DataFrame Reader\n",
    "\n",
    "For more information on loading data, see documentation on [snowflake.snowpark.DataFrameReader](https://docs.snowflake.com/ko/developer-guide/snowpark/reference/python/api/snowflake.snowpark.DataFrameReader.html).\n",
    "\n",
    "First, download the `diamonds` data from\n",
    "https://github.com/tidyverse/ggplot2/blob/882584f915b23cda5091fb69e88f19e8200811bf/data-raw/diamonds.csv and save it in this repo's folder.\n",
    "\n",
    "Once it's downloaded, run the rest of the cells in order to stage the file in Snowflake.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='diamonds.csv', target='diamonds.csv', source_size=2772143, target_size=0, source_compression='NONE', target_compression='NONE', status='SKIPPED', message='')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the diamonds CSV file to the stage we created earlier\n",
    "session.file.put(\"diamonds.csv\", \"@DIAMONDS_ASSETS\", auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "|\"CARAT\"  |\"CUT\"  |\"COLOR\"    |\"CLARITY\"  |\"DEPTH\"  |\"TABLE\"  |\"PRICE\"  |\"X\"    |\"Y\"   |\"Z\"   |\n",
      "-----------------------------------------------------------------------------------------------\n",
      "|1.0      |0.23   |Ideal      |E          |SI2      |61.5     |55.0     |326.0  |3.95  |3.98  |\n",
      "|2.0      |0.21   |Premium    |E          |SI1      |59.8     |61.0     |326.0  |3.89  |3.84  |\n",
      "|3.0      |0.23   |Good       |E          |VS1      |56.9     |65.0     |327.0  |4.05  |4.07  |\n",
      "|4.0      |0.29   |Premium    |I          |VS2      |62.4     |58.0     |334.0  |4.2   |4.23  |\n",
      "|5.0      |0.31   |Good       |J          |SI2      |63.3     |58.0     |335.0  |4.34  |4.35  |\n",
      "|6.0      |0.24   |Very Good  |J          |VVS2     |62.8     |57.0     |336.0  |3.94  |3.96  |\n",
      "|7.0      |0.24   |Very Good  |I          |VVS1     |62.3     |57.0     |336.0  |3.95  |3.98  |\n",
      "|8.0      |0.26   |Very Good  |H          |SI1      |61.9     |55.0     |337.0  |4.07  |4.11  |\n",
      "|9.0      |0.22   |Fair       |E          |VS2      |65.1     |61.0     |337.0  |3.87  |3.78  |\n",
      "|10.0     |0.23   |Very Good  |H          |VS1      |59.4     |61.0     |338.0  |4.0   |4.05  |\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"SUMMARY\"  |\"CARAT\"             |\"CUT\"  |\"COLOR\"    |\"CLARITY\"  |\"DEPTH\"  |\"TABLE\"             |\"PRICE\"             |\"X\"                |\"Y\"                 |\"Z\"                 |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|count      |53940.0             |53940  |53940      |53940      |53940    |53940.0             |53940.0             |53940.0            |53940.0             |53940.0             |\n",
      "|mean       |26970.5             |NULL   |NULL       |NULL       |NULL     |61.74940489432703   |57.45718390804598   |3932.799721913237  |5.731157211716722   |5.734525954764553   |\n",
      "|stddev     |15571.281096942534  |NULL   |NULL       |NULL       |NULL     |1.4326213188335484  |2.2344905628213527  |3989.439738146379  |1.1217607467924935  |1.1421346741235547  |\n",
      "|min        |1.0                 |0.2    |Fair       |D          |I1       |43.0                |43.0                |326.0              |0.0                 |0.0                 |\n",
      "|max        |53940.0             |5.01   |Very Good  |J          |VVS2     |79.0                |95.0                |18823.0            |10.74               |58.9                |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for the data in the CSV file\n",
    "diamonds_schema = StructType([StructField(\"carat\", FloatType()), \n",
    "                              StructField(\"cut\", StringType()),\n",
    "                              StructField(\"color\", StringType()),\n",
    "                              StructField(\"clarity\", StringType()),\n",
    "                              StructField(\"depth\", StringType()),\n",
    "                              StructField(\"table\", FloatType()),\n",
    "                              StructField(\"price\", FloatType()),\n",
    "                              StructField(\"x\", FloatType()),\n",
    "                              StructField(\"y\", FloatType()),\n",
    "                              StructField(\"z\", FloatType())\n",
    "                              ])\n",
    "\n",
    "# Create a Snowpark DataFrame that is configured to load data from the CSV file\n",
    "diamonds_df = session.read.options({\"field_delimiter\": \",\", \"skip_header\": 1}).schema(diamonds_schema).csv(\"@DIAMONDS_ASSETS/diamonds.csv\")\n",
    "diamonds_df.show()\n",
    "\n",
    "# Look at descriptive stats on the DataFrame\n",
    "diamonds_df.describe().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we standardize the category formatting for `CUT` using Snowpark DataFrame operations.\n",
    "\n",
    "This way, when we write to a Snowflake table, there will be no inconsistencies in how the Snowpark DataFrame will read in the column names. Secondly, the feature transformations on categoricals will be easier to encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "|\"CARAT\"  |\"COLOR\"    |\"CLARITY\"  |\"DEPTH\"  |\"TABLE\"  |\"PRICE\"  |\"X\"    |\"Y\"   |\"Z\"   |\"CUT\"  |\n",
      "-----------------------------------------------------------------------------------------------\n",
      "|1.0      |Ideal      |E          |SI2      |61.5     |55.0     |326.0  |3.95  |3.98  |0_23   |\n",
      "|2.0      |Premium    |E          |SI1      |59.8     |61.0     |326.0  |3.89  |3.84  |0_21   |\n",
      "|3.0      |Good       |E          |VS1      |56.9     |65.0     |327.0  |4.05  |4.07  |0_23   |\n",
      "|4.0      |Premium    |I          |VS2      |62.4     |58.0     |334.0  |4.2   |4.23  |0_29   |\n",
      "|5.0      |Good       |J          |SI2      |63.3     |58.0     |335.0  |4.34  |4.35  |0_31   |\n",
      "|6.0      |Very Good  |J          |VVS2     |62.8     |57.0     |336.0  |3.94  |3.96  |0_24   |\n",
      "|7.0      |Very Good  |I          |VVS1     |62.3     |57.0     |336.0  |3.95  |3.98  |0_24   |\n",
      "|8.0      |Very Good  |H          |SI1      |61.9     |55.0     |337.0  |4.07  |4.11  |0_26   |\n",
      "|9.0      |Fair       |E          |VS2      |65.1     |61.0     |337.0  |3.87  |3.78  |0_22   |\n",
      "|10.0     |Very Good  |H          |VS1      |59.4     |61.0     |338.0  |4.0   |4.05  |0_23   |\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fix_values(columnn):\n",
    "    return F.upper(F.regexp_replace(F.col(columnn), '[^a-zA-Z0-9]+', '_'))\n",
    "\n",
    "for col in [\"CUT\"]:\n",
    "    diamonds_df = diamonds_df.with_column(col, fix_values(col))\n",
    "\n",
    "diamonds_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we force headers to uppercase using Snowpark DataFrame operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "|\"CARAT\"  |\"COLOR\"    |\"CLARITY\"  |\"DEPTH\"  |\"TABLE_PCT\"  |\"PRICE\"  |\"X\"    |\"Y\"   |\"Z\"   |\"CUT\"  |\n",
      "---------------------------------------------------------------------------------------------------\n",
      "|1.0      |Ideal      |E          |SI2      |61.5         |55.0     |326.0  |3.95  |3.98  |0_23   |\n",
      "|2.0      |Premium    |E          |SI1      |59.8         |61.0     |326.0  |3.89  |3.84  |0_21   |\n",
      "|3.0      |Good       |E          |VS1      |56.9         |65.0     |327.0  |4.05  |4.07  |0_23   |\n",
      "|4.0      |Premium    |I          |VS2      |62.4         |58.0     |334.0  |4.2   |4.23  |0_29   |\n",
      "|5.0      |Good       |J          |SI2      |63.3         |58.0     |335.0  |4.34  |4.35  |0_31   |\n",
      "|6.0      |Very Good  |J          |VVS2     |62.8         |57.0     |336.0  |3.94  |3.96  |0_24   |\n",
      "|7.0      |Very Good  |I          |VVS1     |62.3         |57.0     |336.0  |3.95  |3.98  |0_24   |\n",
      "|8.0      |Very Good  |H          |SI1      |61.9         |55.0     |337.0  |4.07  |4.11  |0_26   |\n",
      "|9.0      |Fair       |E          |VS2      |65.1         |61.0     |337.0  |3.87  |3.78  |0_22   |\n",
      "|10.0     |Very Good  |H          |VS1      |59.4         |61.0     |338.0  |4.0   |4.05  |0_23   |\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Force headers to uppercase\n",
    "for colname in np.array(diamonds_df.columns):\n",
    "    if str.upper(colname) == \"TABLE\":\n",
    "        new_colname = colname + '_PCT'\n",
    "    else:\n",
    "        new_colname = str.upper(colname)\n",
    "\n",
    "    diamonds_df = diamonds_df.with_column_renamed(colname, new_colname)\n",
    "\n",
    "diamonds_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write cleaned data to a Snowflake table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_df.write.mode('overwrite').save_as_table('diamonds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysnowpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
